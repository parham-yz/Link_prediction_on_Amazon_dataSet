{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K9U1XSGyDn7",
        "outputId": "ff1540ce-37da-4df2-9d18-0fbc093b74a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-scatter\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_scatter-2.0.7-cp37-cp37m-linux_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 4.1MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.7\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-sparse\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_sparse-0.6.10-cp37-cp37m-linux_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.10\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-cluster\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (926kB)\n",
            "\u001b[K     |████████████████████████████████| 931kB 4.0MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Collecting torch-spline-conv\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.9.0%2Bcu102/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (382kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 4.1MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/61/b3f23832120c404673f6759008312ffe8269524a29bf6116d9980e44517b/torch_geometric-1.7.2.tar.gz (222kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.5.1)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.7.2-cp37-none-any.whl size=388143 sha256=ba5d89407be2e2d58a3d1bc5fe2c00cbe523bebcf56c197253c1ec5332023961\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/66/5b/ad17ef7f04b7c425dc6930daac160c3747231b0d65f9ac7972\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 rdflib-5.0.0 torch-geometric-1.7.2\n"
          ]
        }
      ],
      "source": [
        "# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R5YgeiZAxx-l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuMaTjdqyPi5",
        "outputId": "a085e114-24b0-4084-93cb-59397d9517cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/amazon_electronics_computers.npz\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "import torch_geometric.datasets\n",
        "device = torch.device('cuda:0')\n",
        "print(device)\n",
        "data = torch_geometric.datasets.amazon.Amazon('.','Computers').data.to(device)\n",
        "# data = torch_geometric.datasets.amazon.Amazon('.','Computers').data.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-ftsAbqIp2gd"
      },
      "outputs": [],
      "source": [
        "class GNNEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim,output_dim):\n",
        "        super(GNNEncoder, self).__init__()\n",
        "\n",
        "        self.conv1 = pyg_nn.GCNConv(input_dim, hidden_dim*4)\n",
        "        self.conv2 = pyg_nn.GCNConv(hidden_dim*4, hidden_dim*2)\n",
        "        self.conv3 = pyg_nn.GCNConv(hidden_dim*2, hidden_dim)\n",
        "\n",
        "        self.ln1 = nn.Linear(hidden_dim*4,hidden_dim*4)\n",
        "        self.ln2 = nn.Linear(hidden_dim*2,hidden_dim*2)\n",
        "        self.ln3 = nn.Linear(hidden_dim,output_dim)\n",
        "\n",
        "        self. bias = nn.Parameter(torch.tensor(-10,dtype = float))\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.bn2 = nn.BatchNorm1d(1)\n",
        "        self.dropout = 0.25\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, data, do_mult = True):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x,edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.tanh(self.ln1(x))+x\n",
        "\n",
        "        x = self.conv2(x,edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.tanh(self.ln2(x))+x\n",
        "\n",
        "        x = self.conv3(x,edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.ln3(x)\n",
        "\n",
        "        if do_mult:\n",
        "            x = (x@torch.transpose(x, 0, 1))\n",
        "            shape = x.shape\n",
        "            x = self.bn2(x.view(-1,1)).view(shape)\n",
        "            x = torch.sigmoid(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class GNNDecoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim,ouput_dim):\n",
        "        super(GNNDecoder, self).__init__()\n",
        "\n",
        "        self.ln11 = nn.Linear(input_dim,hidden_dim*2)\n",
        "        self.ln12 = nn.Linear(input_dim,hidden_dim*2)\n",
        "\n",
        "        self.ln2 = nn.Linear(hidden_dim*4,hidden_dim)\n",
        "        self.ln3 = nn.Linear(hidden_dim,ouput_dim)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(input_dim)\n",
        "        self.bn2 = nn.BatchNorm1d(input_dim)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # x1 = self.bn1(x1)\n",
        "        # x2 = self.bn2(x2)\n",
        "\n",
        "        x1 = self.ln11(x1)\n",
        "        x1 = F.relu(x1)\n",
        "\n",
        "        x2 = self.ln12(x2)\n",
        "        x2 = F.relu(x2)\n",
        "\n",
        "        x = torch.cat([x1,x2],1)\n",
        "\n",
        "        x = self.ln2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.ln3(x)\n",
        "        x = torch.sigmoid(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def loss(pred,ture):\n",
        "    return -10*((2*ture*torch.log(pred+10e-6)).mean() + ((1-ture)*(torch.log(1-pred+10e-6))).mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "My-6pzblblMu"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "A = to_dense_adj(data.edge_index).to(device)\n",
        "A = A.view(A.shape[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fkazRWEh8tbZ"
      },
      "outputs": [],
      "source": [
        "enc = GNNEncoder(data.x.shape[1],32,32*4).to(device)\n",
        "\n",
        "# loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10]).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TWyJAxwEbfM_"
      },
      "outputs": [],
      "source": [
        "dec = GNNDecoder(32*4,16,1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aVdBLegb4xOd",
        "outputId": "8219a222-5e67-4be9-8e85-5ad145b578f0"
      },
      "outputs": [],
      "source": [
        "opt = optim.Adam(enc.parameters(), lr=0.005)\n",
        "enc.train(True)\n",
        "\n",
        "for ep in range(8000):\n",
        "    pred = enc(data)\n",
        "\n",
        "    pre = (A*pred).sum()/pred.sum()\n",
        "    re  = (A*pred).sum()/A.sum()\n",
        "    l = loss(pred.view(-1),A.view(-1))\n",
        "        \n",
        "    opt.zero_grad()\n",
        "    l.backward()\n",
        "    opt.step()\n",
        "\n",
        "    if ep%10 == 0:\n",
        "        print(ep,f' Loss: {float(l):.6f}  >>  {float(pre):.6f}  {float(re):.6f} ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfedE3qi2nHm",
        "outputId": "68fc459b-2606-42ec-80e5-0bb2caf058a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0  Loss: 0.587055  >>  0.812423  0.806773 \n",
            "10  Loss: 0.623688  >>  0.800251  0.794997 \n",
            "20  Loss: 0.625682  >>  0.804427  0.798473 \n",
            "30  Loss: 0.584389  >>  0.815027  0.803516 \n",
            "40  Loss: 0.656750  >>  0.797663  0.795675 \n",
            "50  Loss: 0.587456  >>  0.808156  0.813364 \n",
            "60  Loss: 0.638162  >>  0.796838  0.791502 \n",
            "70  Loss: 0.648301  >>  0.798887  0.793970 \n",
            "80  Loss: 0.641511  >>  0.798966  0.792416 \n",
            "90  Loss: 0.600198  >>  0.800879  0.808404 \n",
            "100  Loss: 0.627120  >>  0.801716  0.795159 \n",
            "110  Loss: 0.621997  >>  0.800191  0.802906 \n",
            "120  Loss: 0.630683  >>  0.799267  0.797689 \n",
            "130  Loss: 0.596155  >>  0.803791  0.808712 \n",
            "140  Loss: 0.630822  >>  0.797475  0.797440 \n",
            "150  Loss: 0.603256  >>  0.807694  0.798866 \n",
            "160  Loss: 0.622459  >>  0.796801  0.802240 \n",
            "170  Loss: 0.617845  >>  0.802185  0.803489 \n",
            "180  Loss: 0.661157  >>  0.791817  0.801703 \n",
            "190  Loss: 0.610825  >>  0.804092  0.796150 \n",
            "200  Loss: 0.600653  >>  0.807569  0.795699 \n",
            "210  Loss: 0.629090  >>  0.795383  0.806847 \n",
            "220  Loss: 0.564348  >>  0.814341  0.806838 \n",
            "230  Loss: 0.627517  >>  0.798306  0.799411 \n",
            "240  Loss: 0.615291  >>  0.796978  0.802816 \n",
            "250  Loss: 0.617611  >>  0.803714  0.800429 \n",
            "260  Loss: 0.626273  >>  0.794398  0.803006 \n",
            "270  Loss: 0.615938  >>  0.798556  0.810508 \n",
            "280  Loss: 0.614726  >>  0.798629  0.801984 \n",
            "290  Loss: 0.613515  >>  0.797272  0.808144 \n",
            "300  Loss: 0.614957  >>  0.803595  0.801720 \n",
            "310  Loss: 0.610179  >>  0.798928  0.808737 \n",
            "320  Loss: 0.626193  >>  0.801615  0.799899 \n",
            "330  Loss: 0.596003  >>  0.804444  0.805291 \n",
            "340  Loss: 0.632410  >>  0.799588  0.799022 \n",
            "350  Loss: 0.607976  >>  0.801790  0.807714 \n",
            "360  Loss: 0.584218  >>  0.806828  0.807802 \n",
            "370  Loss: 0.609402  >>  0.807747  0.798903 \n",
            "380  Loss: 0.598666  >>  0.808780  0.802899 \n",
            "390  Loss: 0.627981  >>  0.796525  0.797354 \n",
            "400  Loss: 0.628277  >>  0.800358  0.801766 \n",
            "410  Loss: 0.625494  >>  0.801726  0.801739 \n",
            "420  Loss: 0.642952  >>  0.792634  0.803934 \n",
            "430  Loss: 0.619829  >>  0.799964  0.808622 \n",
            "440  Loss: 0.617132  >>  0.795047  0.806664 \n",
            "450  Loss: 0.584796  >>  0.808201  0.809019 \n",
            "460  Loss: 0.606680  >>  0.800155  0.808383 \n",
            "470  Loss: 0.625358  >>  0.797515  0.806934 \n",
            "480  Loss: 0.608029  >>  0.801503  0.807948 \n",
            "490  Loss: 0.579984  >>  0.811893  0.810886 \n",
            "500  Loss: 0.631578  >>  0.796755  0.801696 \n",
            "510  Loss: 0.615868  >>  0.800583  0.806197 \n",
            "520  Loss: 0.609792  >>  0.799388  0.807245 \n",
            "530  Loss: 0.612363  >>  0.803144  0.804550 \n",
            "540  Loss: 0.600146  >>  0.803844  0.811052 \n",
            "550  Loss: 0.613348  >>  0.801533  0.805040 \n",
            "560  Loss: 0.605293  >>  0.803841  0.809717 \n",
            "570  Loss: 0.647108  >>  0.797723  0.796002 \n",
            "580  Loss: 0.639302  >>  0.796893  0.803508 \n",
            "590  Loss: 0.614730  >>  0.801705  0.801181 \n",
            "600  Loss: 0.602424  >>  0.804931  0.807169 \n",
            "610  Loss: 0.617243  >>  0.808183  0.798190 \n",
            "620  Loss: 0.611405  >>  0.805590  0.803700 \n",
            "630  Loss: 0.642683  >>  0.792408  0.801761 \n",
            "640  Loss: 0.605820  >>  0.805937  0.798281 \n",
            "650  Loss: 0.601768  >>  0.801328  0.806160 \n",
            "660  Loss: 0.596733  >>  0.803481  0.802728 \n",
            "670  Loss: 0.607208  >>  0.802934  0.813286 \n",
            "680  Loss: 0.636517  >>  0.798706  0.802780 \n",
            "690  Loss: 0.619611  >>  0.798627  0.810984 \n",
            "700  Loss: 0.612718  >>  0.799163  0.803098 \n",
            "710  Loss: 0.618776  >>  0.797645  0.801840 \n",
            "720  Loss: 0.634353  >>  0.795883  0.803036 \n",
            "730  Loss: 0.585715  >>  0.811760  0.806406 \n",
            "740  Loss: 0.605417  >>  0.806401  0.804350 \n",
            "750  Loss: 0.594448  >>  0.807921  0.811940 \n",
            "760  Loss: 0.602147  >>  0.806710  0.803538 \n",
            "770  Loss: 0.635340  >>  0.799512  0.797062 \n",
            "780  Loss: 0.615275  >>  0.809817  0.797066 \n",
            "790  Loss: 0.597478  >>  0.808239  0.808222 \n",
            "800  Loss: 0.615670  >>  0.803629  0.804966 \n",
            "810  Loss: 0.602547  >>  0.803464  0.804531 \n",
            "820  Loss: 0.633858  >>  0.792124  0.806682 \n",
            "830  Loss: 0.574121  >>  0.811773  0.805645 \n",
            "840  Loss: 0.638335  >>  0.797592  0.792569 \n",
            "850  Loss: 0.594481  >>  0.812926  0.805084 \n",
            "860  Loss: 0.645331  >>  0.798741  0.806438 \n",
            "870  Loss: 0.586664  >>  0.813350  0.798419 \n",
            "880  Loss: 0.600351  >>  0.805304  0.806369 \n",
            "890  Loss: 0.623236  >>  0.800518  0.805075 \n",
            "900  Loss: 0.624153  >>  0.805312  0.802267 \n",
            "910  Loss: 0.617448  >>  0.801566  0.810189 \n",
            "920  Loss: 0.613273  >>  0.801624  0.804037 \n",
            "930  Loss: 0.625749  >>  0.798563  0.805471 \n",
            "940  Loss: 0.599923  >>  0.808191  0.808747 \n",
            "950  Loss: 0.599717  >>  0.813796  0.804371 \n",
            "960  Loss: 0.613500  >>  0.805002  0.802410 \n",
            "970  Loss: 0.608951  >>  0.807113  0.803868 \n",
            "980  Loss: 0.631965  >>  0.803311  0.797696 \n",
            "990  Loss: 0.584523  >>  0.812807  0.804857 \n"
          ]
        }
      ],
      "source": [
        "opt = optim.Adam(dec.parameters(), lr=0.00005)\n",
        "loss = nn.BCELoss()\n",
        "batch_size = 256*16\n",
        "enc.train(False)\n",
        "emb = enc(data,False)\n",
        "emb = emb.detach()\n",
        "\n",
        "emb = emb/emb.var() - emb.mean()\n",
        "\n",
        "for ep in range(1000):\n",
        "    \n",
        "\n",
        "    indices = torch.randint(0,data.edge_index.shape[1],(int(batch_size/2),))\n",
        "    x1 = emb[data.edge_index[0,indices]]\n",
        "    x2 = emb[data.edge_index[1,indices]]\n",
        "    \n",
        "\n",
        "\n",
        "    num_neg_smp = 0\n",
        "    tx1 = []\n",
        "    tx2 = []\n",
        "    for i,j in torch.randint(0,emb.shape[0],(batch_size*4,2)):\n",
        "        if A[i,j] == 0 and num_neg_smp < batch_size/2:\n",
        "            tx1.append(emb[i])\n",
        "            tx2.append(emb[j])\n",
        "            num_neg_smp += 1\n",
        "        if num_neg_smp > batch_size/2:\n",
        "            break\n",
        "\n",
        "    perm = torch.randperm(batch_size)\n",
        "    x1 = torch.cat([x1,torch.stack(tx1).to(device)],0)\n",
        "    x1 = x1[perm]\n",
        "    x2 = torch.cat([x2,torch.stack(tx2).to(device)],0)\n",
        "    x2 = x2[perm]\n",
        "    \n",
        "    y = torch.cat([torch.ones([int(batch_size/2)]),torch.zeros([int(batch_size/2)])],0).to(device)\n",
        "    y = y[perm]\n",
        " \n",
        "\n",
        "    pred1 = dec(x1,x2).view(-1)\n",
        "    pred2 = dec(x2,x1).view(-1)\n",
        "    # print(pred1.min(),pred1.max())\n",
        "    opt.zero_grad()\n",
        "    # pre = (y*pred1).sum()/(pred1.sum()+10e-6)\n",
        "    # re  = (y*pred1).sum()/(y.sum()+10e-6)\n",
        "    # l = -(re*pre)/(pre+ re)\n",
        "    l = loss(pred1,y) + loss(pred2,y)\n",
        "\n",
        "    l.backward()\n",
        "        \n",
        "    opt.step()\n",
        "\n",
        "    if ep%10 == 0:\n",
        "        pre = (y*pred1).sum()/(pred1.sum()+10e-6)\n",
        "        re  = (y*pred1).sum()/(y.sum()+10e-6)\n",
        "        print(ep,f' Loss: {float(l):.6f}  >>  {float(pre):.6f}  {float(re):.6f} ')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "gnn_lp_(3).ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8176438c5a17c06f3f3c8391faf90c450e02c98114053005859fe8b14d667a3b"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}